# Задание 2 — CUDA: префиксная сумма (scan) с использованием shared memory

## 1. Цель задания

Нужно реализовать CUDA-программу для вычисления **префиксной суммы массива** (scan):

- для каждого индекса `i` нужно получить сумму всех элементов от `0` до `i`.

В этом решении реализован **inclusive scan**:

- `out[i] = in[0] + in[1] + ... + in[i]`

По заданию также требуется:

- использовать **разделяемую память (shared memory)** для оптимизации,
- проверить корректность на тестовом массиве (сравнить с CPU).


## 2. Идея решения

Префиксная сумма на GPU сложнее редукции, потому что каждому элементу нужен “свой” результат.

Здесь используется стандартный подход “scan по блокам”:

1) **Скан внутри каждого блока** в shared memory (быстро).
2) Сохранить **сумму каждого блока** в массив `block_sums`.
3) Сделать scan по `block_sums` (получить префиксы блоков).
4) Добавить каждому элементу блока **оффсет** (сумму всех предыдущих блоков).

Так можно посчитать scan для массива любого размера, даже если он намного больше одного блока.


## 3. CPU-эталон (для проверки)

Функция `cpu_inclusive_scan(...)` делает обычный последовательный inclusive scan:

- идёт слева направо,
- накапливает сумму `acc`,
- записывает `out[i] = acc`.

Это используется как “правильный ответ” для проверки GPU результата.


## 4. Как работает scan внутри блока (Blelloch в shared memory)

Внутри одного блока используется алгоритм **Blelloch exclusive scan** (в shared memory):

- сначала делаем **exclusive scan**,
- потом переводим его в **inclusive**.

### 4.1 Почему сначала exclusive?
Blelloch классически строится как exclusive scan:

- `exclusive[i] = sum(in[0..i-1])`

Потом inclusive легко получить так:

- `inclusive[i] = exclusive[i] + in[i]`

## 5. Ядро 1: scan внутри блока + суммы блоков

### `block_scan_kernel(in, out, block_sums, n)`

Это ядро делает сразу две вещи:

1) считает **inclusive scan внутри блока** и пишет результат в `out`,
2) считает **сумму всего блока** и записывает в `block_sums[blockIdx.x]`.

#### Шаги внутри ядра:

1) Каждый поток загружает свой элемент в shared:
- `gid = blockIdx.x * blockDim.x + tid`
- если `gid < n`, берём `in[gid]`, иначе `0`
- кладём в `s[tid]`

2) Выполняем `blelloch_exclusive_scan(s)`:
- результат в `s[tid]` становится exclusive prefix.

3) Переводим в inclusive:
- `inclusive = s[tid] + x`
- если `gid < n`, записываем `out[gid] = inclusive`

4) Сохраняем сумму блока:
- находим сколько в блоке реально валидных элементов (`valid`)
- берём inclusive у последнего валидного элемента
- записываем в `block_sums[blockIdx.x]`


## 6. Рекурсивный scan блоков (GPU)

### `gpu_inclusive_scan(d_in, d_out, n, threads)`

Это функция, которая делает scan для массива любого размера:

1) запускает `block_scan_kernel` → получаем:
   - `d_out` = scan внутри блоков
   - `d_block_sums` = суммы блоков

2) если блок всего один (`blocks == 1`) — scan готов.

3) если блоков больше 1:
   - рекурсивно делаем scan по `d_block_sums` → получаем `d_scanned_block_sums`
   - добавляем оффсеты всем блокам через `add_offsets_kernel`


## 7. Ядро 2: добавление оффсетов блоков

### `add_offsets_kernel(out, block_offsets, n)`

После первого шага каждый блок содержит scan “с нуля”, то есть без учёта предыдущих блоков.

Чтобы получить глобальный scan:

- каждому элементу блока `b` нужно прибавить сумму всех предыдущих блоков.

Оффсет берётся так:

- `offset = (b == 0) ? 0 : block_offsets[b - 1]`

Затем:

- `out[gid] += offset`


## 8. Почему используется shared memory

Shared memory применяется в `block_scan_kernel` для scan внутри блока:

- обращения в shared намного быстрее, чем в global memory,
- редукция/scan внутри блока требует многократных обращений к данным,
- поэтому shared даёт существенный выигрыш по скорости.


## 9. Измерение времени

В `main()` время измеряется через CUDA Events:

- `cudaEventRecord(start)`
- запускается `gpu_inclusive_scan(...)`
- `cudaEventRecord(stop)` + `cudaEventSynchronize(stop)`
- `cudaEventElapsedTime(&ms, start, stop)`

Выводится:

- `GPU scan time (ms)`


## 10. Проверка корректности

После выполнения scan:

- копируем `d_out` → `h_out`
- сравниваем с `h_ref` (CPU scan)

Считаем:

- `Max abs error = max(|h_out[i] - h_ref[i]|)`

Если ошибка очень маленькая, значит всё работает правильно.


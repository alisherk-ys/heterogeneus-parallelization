# Задача №2 — OpenCL: параллельное умножение матриц (A[N×M] · B[M×K] = C[N×K]) + проверка на CPU

## Цель задания

Нужно реализовать OpenCL-программу для **параллельного умножения матриц**:

- Матрица **A** размера **N×M**
- Матрица **B** размера **M×K**
- Результат **C** размера **N×K**

Формула:
- `C[i, j] = Σ (A[i, t] * B[t, j])`, где `t = 0..M-1`

Далее требуется:

- передать размеры **N, M, K** в ядро как аргументы,
- правильно настроить **global** и **local** размеры рабочих групп,
- проверить корректность: сравнить результат OpenCL с **последовательной реализацией на CPU**.


## Идея решения

Решение состоит из двух частей:

### 2.1 OpenCL-версия (параллельно)
- Каждый work-item вычисляет **один элемент** матрицы `C[row, col]`.
- Индексы берутся из двумерного пространства:
  - `row = get_global_id(0)`
  - `col = get_global_id(1)`
- Для вычисления `C[row, col]` выполняется цикл по `t` от `0` до `M-1`.

### 2.2 CPU-версия (последовательно)
- Обычный тройной цикл `i-j-t`,
- считает `Cref` как эталон,
- затем сравниваем `C` (OpenCL) и `Cref` (CPU) по максимальной ошибке.

## Реализация ядра (kernel.cl)

### Ядро `matmul_basic`
Ядро получает:

- указатели на массивы `A`, `B`, `C` (в глобальной памяти),
- размеры `N, M, K`.

Логика:

1) Определяем координаты элемента результата:
- `row = get_global_id(0)`
- `col = get_global_id(1)`

2) Проверяем границы (на случай, если global размер округляли вверх):
- если `row < N` и `col < K`

3) Считаем сумму по `t`:
- `sum += A[row * M + t] * B[t * K + col]`

4) Записываем:
- `C[row * K + col] = sum`

Это базовая (naive) версия умножения: без тайлинга и shared/local памяти.


## Реализация host-программы (main.cpp) — по шагам

### Шаг 1. Выбор устройства
Программа пытается выбрать:

1) сначала **GPU** (если есть),
2) если GPU нет — **CPU**.

После выбора печатается:
- имя платформы,
- имя устройства  


### Шаг 2. Создание контекста и очереди
- создаётся OpenCL контекст `clCreateContext`,
- создаётся очередь `clCreateCommandQueue` с флагом:
  - `CL_QUEUE_PROFILING_ENABLE`  
(профилирование включено, чтобы при желании можно было измерять kernel-время через events).


### Шаг 3. Загрузка и компиляция ядра
- читается файл `kernel_matmul.cl`,
- создаётся OpenCL program,
- компилируется через `clBuildProgram`,
- создаётся kernel `matmul_basic`.


### Шаг 4. Подготовка матриц A, B
- `A` размера `N*M`, `B` размера `M*K`
- заполняются случайными `float`
- `C` и `Cref` размером `N*K` инициализируются нулями

В коде для теста используются размеры:
- `N = M = K = 512`


### Шаг 5. Создание буферов и копирование данных
Создаются буферы:

- `bufA` (READ_ONLY)
- `bufB` (READ_ONLY)
- `bufC` (WRITE_ONLY)

Далее `A` и `B` копируются на устройство через `clEnqueueWriteBuffer`.

### Шаг 6. Передача аргументов в ядро
В kernel передаются:

- `bufA`, `bufB`, `bufC`,
- размеры `N`, `M`, `K`.



## Настройка global/local размеров (очень важно по заданию)

### 1. Local size (размер рабочей группы)
В коде:
- `local = {16, 16}`

То есть одна группа = 256 work-items.

### 2. Global size (размер всей сетки)
Нужно покрыть матрицу результата `C` размера `N×K`.

Но global размеры обычно должны быть кратны local, поэтому делается округление вверх:

- `global[0] = ceil(N / local[0]) * local[0]`
- `global[1] = ceil(K / local[1]) * local[1]`

Из-за этого в kernel есть проверка:
- `if (row < N && col < K)`


## Проверка корректности (OpenCL vs CPU)

После выполнения OpenCL:

- результат `C` считывается на CPU.

Далее считается CPU эталон:

- `cpu_matmul(A, B, Cref, N, M, K)`

После этого считается максимальная ошибка:

- `max_err = max(|C[i] - Cref[i]|)`

Если `max_err` маленькая (обычно `~1e-4` или меньше), значит всё корректно.

---

## Время выполнения

В текущем коде замеряется:

- **CPU time** — время последовательного умножения `cpu_matmul(...)`.

OpenCL kernel-time через event profiling **можно добавить**, но по текущему коду выводится только CPU время и ошибка.

Если нужно для отчёта “CPU vs GPU”, логично дополнить выводом времени OpenCL kernel через `clGetEventProfilingInfo(event, ...)` (аналогично задаче №1).



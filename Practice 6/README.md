# Практическая работа №6  
## Программирование на OpenCL для CPU и GPU



## Цель работы

- Изучение основ программирования на OpenCL.
- Разработка кросс-платформенного приложения для выполнения параллельных вычислений на CPU и GPU.



## Описание

В рамках данной практической работы необходимо разработать приложение, выполняющее операцию элементного сложения двух массивов.  
Программа должна быть написана с использованием OpenCL и запущена как на CPU, так и на GPU для сравнения производительности.



## Задача №1

### 1. Подготовка окружения

1. Установите необходимые драйверы для OpenCL на вашей системе:
   - Для CPU: установите драйверы от производителя процессора (Intel, AMD).
   - Для GPU: установите драйверы от производителя видеокарты (NVIDIA, AMD).

2. Убедитесь, что OpenCL-библиотеки доступны в вашей системе:
   - Linux:
     ```
     /usr/lib/libOpenCL.so
     ```
   - Windows:
     ```
     OpenCL.dll
     ```

3. Настройте среду разработки (например, VS Code, CLion или Visual Studio).


### 2. Реализация задачи

#### Шаг 1. Создайте ядро OpenCL (файл `kernel.cl`)

Напишите ядро, выполняющее операцию сложения двух массивов:

```c
__kernel void vector_add(__global const float* A,
                         __global const float* B,
                         __global float* C)
{
    int id = get_global_id(0); // Определение глобального ID
    C[id] = A[id] + B[id];     // Выполнение операции сложения
}
```

#### Шаг 2. Создайте программу на C/C++

Реализуйте программу, которая:

1. Инициализирует платформу и устройство OpenCL.

2. Создаёт контекст и командную очередь.

3. Загружает и компилирует ядро.

4. Подготавливает данные (массивы A, B и C).

5. Выполняет ядро и считывает результаты.

#### Шаг 3. Выполните программу

1. Скомпилируйте код с использованием OpenCL-библиотеки.

2. Измерьте время выполнения программы на CPU и GPU (например, с использованием clock() или профилировщиков).

#### Шаг 4. Сравните производительность

Сравните производительность выполнения программы на CPU и GPU.
Отчёт должен содержать:

- Время выполнения на CPU.

- Время выполнения на GPU.

- График сравнения.

## Задача №2
## Описание задачи

Реализуйте программу для параллельного умножения двух матриц с использованием OpenCL.

Матрицы имеют следующие размеры:

Матрица A — N × M

Матрица B — M × K

Результирующая матрица C — N × K

#### Шаг 1. Создайте ядро OpenCL для матричного умножения
#### Шаг 2. Реализуйте программу

1. Подготовьте матрицы A, B и C.

2. Передайте размеры матриц (N, M, K) в качестве аргументов ядра.

3. Настройте размеры рабочей группы, соответствующие размеру матрицы C (глобальная рабочая группа).

#### Шаг 3. Проверьте корректность результатов

Сравните результаты OpenCL с последовательной реализацией матричного умножения на CPU.

## Контрольные вопросы

### 1. Какие основные типы памяти используются в OpenCL?

**Редукция** — это операция, которая сводит массив данных к одному значению, например сумме, минимуму или максимуму элементов.
Результатом редукции является один итоговый элемент.

**Сканирование** (prefix sum) — это операция, при которой для каждого элемента массива вычисляется накопленный результат от начала массива до текущего элемента.
Результатом сканирования является массив той же длины, где каждый элемент зависит от предыдущих.

### 2. Как настроить глобальную и локальную рабочую группу?

Для оптимизации используются следующие типы памяти CUDA:

- Глобальная память (global memory) — основное хранилище данных; имеет высокую задержку, поэтому её использование стараются минимизировать.

- Разделяемая память (shared memory) — быстрая память внутри блока потоков; активно используется для параллельной редукции и сканирования.

- Регистры — самая быстрая память, используется для локальных переменных внутри потоков.

- Константная память (constant memory) — может применяться для хранения неизменяемых параметров алгоритма (например, размеров).

Наибольший вклад в ускорение дают shared memory и регистры, так как они существенно уменьшают число обращений к глобальной памяти.

### 3. Чем отличается OpenCL от CUDA?

Префиксную сумму на GPU можно оптимизировать следующими способами:

- Использовать алгоритм Blelloch или аналогичные параллельные схемы вместо наивного Hillis–Steele.

- Выполнять основные вычисления в shared memory, чтобы снизить задержки доступа.

- Разбивать массив на блоки и выполнять локальное сканирование внутри блока.

- Применять иерархический подход: сначала сканировать блоки, затем добавлять оффсеты блоков.

- Минимизировать количество запусков kernel и обращений к глобальной памяти.

### 4. Какие преимущества даёт использование OpenCL?

Сканирование применяется во многих практических задачах, например:

- **Сортировка (Radix Sort)** - для вычисления позиций элементов.

- **Фильтрация данных** - определение новых индексов элементов, прошедших условие.

- **Построение гистограмм** - накопление частот.

- **Обработка графов** - формирование CSR-структур.

- **Параллельная обработка массивов** - вычисление кумулятивных сумм, вероятностей и распределений.

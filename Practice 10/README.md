# Практическая работа №10.
## Задание 1. Анализ производительности CPU-параллельной программы (OpenMP)
Разработайте параллельную программу на C++ с использованием OpenMP для обработки
большого массива данных (например, вычисление суммы, среднего значения и
дисперсии).
### Требуется:
- реализовать базовую параллельную версию;
- выполнить профилирование программы с использованием omp_get_wtime() и/или
профилировщика (Intel VTune, gprof);
- определить:
  - долю параллельной и последовательной части программы;
  - влияние числа потоков на ускорение;
- проанализировать результаты в контексте закона Амдала.
## Задание 2. Оптимизация доступа к памяти на GPU (CUDA)
Реализуйте ядро CUDA для обработки массива данных, демонстрирующее разные
паттерны доступа к памяти.
### Требуется:
1. реализовать две версии ядра:
  - с эффективным (коалесцированным) доступом к глобальной памяти;
  - с неэффективным доступом к памяти;
2. измерить время выполнения с использованием cudaEvent;
3. провести оптимизацию за счёт:
  - использования разделяемой памяти;
  - изменения организации потоков;
4. сравнить результаты и сделать выводы о влиянии доступа к памяти на производительность GPU.
## Задание 3. Профилирование гибридного приложения CPU + GPU
Разработайте гибридную программу, в которой часть вычислений выполняется на CPU, а
часть — на GPU.
### Требуется:
1. реализовать гибридный алгоритм обработки массива данных;
2. использовать асинхронную передачу данных (cudaMemcpyAsync) и CUDA streams;
3. выполнить профилирование приложения:
  - определить накладные расходы передачи данных;
  - выявить узкие места при взаимодействии CPU и GPU;
4. предложить и реализовать одну оптимизацию, уменьшающую накладные расходы.
## Задание 4. Анализ масштабируемости распределённой программы (MPI)
Реализуйте распределённую программу на MPI для вычисления агрегатной функции над
большим массивом (например, сумма, минимум, максимум).
### Требуется:
- измерить время выполнения при различном числе процессов;
- оценить strong scaling и weak scaling;
- проанализировать влияние коммуникационных операций (MPI_Reduce,
MPI_Allreduce);
- сделать вывод о масштабируемости алгоритма и его практических ограничениях.
## Контрольные вопросы
### 1. В чём отличие измерения времени выполнения от профилирования?
Измерение времени выполнения показывает общее время работы программы или её части, но не раскрывает причины затрат времени. Профилирование, в отличие от простого замера времени, позволяет детально проанализировать, какие функции, участки кода или операции потребляют наибольшую долю времени и ресурсов, выявляя реальные узкие места.
### 2. Какие виды узких мест характерны для CPU, GPU и распределённых программ?
Для CPU-программ типичными узкими местами являются ограниченное количество ядер, неэффективное использование кэш-памяти и последовательные участки кода. Для GPU-программ основными узкими местами выступают пропускная способность памяти, некоалесцированный доступ и задержки при передаче данных между CPU и GPU. В распределённых программах узкими местами чаще всего становятся коммуникации между процессами, задержки сети и коллективные операции MPI.
### 3. Почему увеличение числа потоков или процессов не всегда приводит к ускорению?
Увеличение числа потоков или процессов не всегда приводит к ускорению из-за накладных расходов на синхронизацию и обмен данными, а также из-за наличия последовательных участков кода. При большом количестве потоков возрастает конкуренция за ресурсы (кэш, память, сеть), что может привести к снижению эффективности и даже к замедлению выполнения.
### 4. Как законы Амдала и Густафсона применяются при анализе масштабируемости?
Закон Амдала показывает, что максимальное ускорение программы ограничено долей её последовательной части, и применяется для оценки strong scaling при фиксированном объёме задачи. Закон Густафсона, наоборот, учитывает увеличение объёма задачи с ростом числа процессоров и используется для анализа weak scaling, демонстрируя потенциальную эффективность параллелизма при масштабировании задачи.
### 5. Какие факторы наиболее критичны для производительности гибридных приложений?
Для гибридных приложений (CPU+GPU, MPI+OpenMP) критичны баланс распределения нагрузки между вычислительными устройствами, эффективность передачи данных между CPU и GPU, минимизация синхронизаций, а также согласованное использование параллельных уровней, чтобы вычисления и коммуникации не блокировали друг друга.

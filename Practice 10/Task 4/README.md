# Задание 4 — Анализ масштабируемости распределённой программы (MPI)

## 1. Цель задания

Нужно реализовать MPI-программу для вычисления агрегатных функций над большим массивом (например, **сумма / минимум / максимум**) и оценить её масштабируемость:

- измерить время при разном числе процессов;
- оценить **strong scaling** и **weak scaling**;
- проанализировать влияние коммуникаций (**MPI_Reduce** и **MPI_Allreduce**);
- сделать вывод о масштабируемости и практических ограничениях.

---

## 2. Что делает программа

Каждый процесс работает со **своей частью массива** `a[]` и вычисляет локальные агрегаты:

- локальная сумма `lsum`
- локальный минимум `lmin`
- локальный максимум `lmax`

Далее локальные результаты объединяются в глобальные двумя режимами:

- через `MPI_Reduce` (глобальные значения гарантированно есть на `rank = 0`)
- через `MPI_Allreduce` (глобальные значения получают **все** процессы)

Локальная агрегация выполняется функцией `local_aggregate(...)` — один линейный проход по локальному массиву.

---

## 3. Strong scaling и weak scaling (как интерпретировать)

### 3.1 Strong scaling
**Strong scaling** — фиксируем общий размер задачи `Global N`, увеличиваем число процессов `P`.

Идеально: время `T(P)` уменьшается примерно как `T(1)/P`, но на практике рост коммуникаций и накладных расходов снижает ускорение.

В программе strong scaling включается режимом:
- `mode = "strong"`

Тогда:
- `global_N = N_arg` (фиксированный)
- `local_N` уменьшается при росте `P`

### 3.2 Weak scaling
**Weak scaling** — фиксируем размер работы на процесс `Local N`, увеличиваем число процессов `P`, а общий объём растёт как `Global N = Local N * P`.

Идеально: `T(P)` остаётся примерно постоянным (потому что на каждый процесс нагрузка одинаковая), но коммуникации обычно растут, поэтому время может увеличиваться.

В программе weak scaling включается режимом:
- `mode = "weak"`

Тогда:
- `local_N = N_arg` (фиксированный на процесс)
- `global_N = local_N * P`

---

## 4. Коммуникации: MPI_Reduce vs MPI_Allreduce

### 4.1 MPI_Reduce
`MPI_Reduce` собирает результат только на одном процессе (обычно `rank=0`).

Плюсы:
- меньше “давления” на сеть по сравнению с ситуациями, когда всем нужны данные.

Минусы:
- остальные процессы глобальный результат не получают (если это нужно — придётся рассылать дополнительно).

В коде режим включается:
- `rmode = "reduce"`

### 4.2 MPI_Allreduce
`MPI_Allreduce` делает reduce + доставляет итог **всем** процессам.

Плюсы:
- каждый процесс получает глобальный результат (удобно для дальнейших шагов вычислений).

Минусы:
- обычно дороже по коммуникациям, чем `MPI_Reduce`, особенно на больших `P`.

В коде режим включается:
- `rmode = "allreduce"`

---

## 5. Как измеряется время и что именно профилируется

Программа делит один прогон на этапы (в секундах), используя `MPI_Wtime()`:

- `gen` — генерация локальных данных (создание массива на каждом процессе)
- `comp` — локальные вычисления (sum/min/max по локальному массиву)
- `comm` — коммуникации (`MPI_Reduce` или `MPI_Allreduce`)
- `total` — общее время итерации (включая барьеры)

Чтобы результаты были стабильнее:
- выполняется несколько прогонов `iters`,
- считается среднее время по прогонам,
- затем берётся **максимум по всем процессам** через `MPI_Allreduce(..., MPI_MAX, ...)`.

Почему берётся максимум:
- общая скорость распределённой программы определяется самым медленным процессом (эффект “bottleneck”).

---

## 6. Что означает “доля коммуникаций” и как она используется

В конце выводится метрика:
- `Comm share = Comm / Total`

Интерпретация:
- если `Comm share` маленькая → программа преимущественно вычислительная, масштабируется лучше;
- если `Comm share` растёт с увеличением процессов → коммуникации становятся узким местом, и ускорение ухудшается.

---

## 7. Как запускать и собирать измерения (типовые сценарии)

### 7.1 Компиляция
- `mpicxx -O2 mpi_scaling.cpp -o mpi_scaling`

### 7.2 Strong scaling (фиксированный Global N)
Запускаем с разным числом процессов, общий `N` фиксирован:

- `mpirun -np 1  ./mpi_scaling strong reduce    10000000 20`
- `mpirun -np 2  ./mpi_scaling strong reduce    10000000 20`
- `mpirun -np 4  ./mpi_scaling strong reduce    10000000 20`
- `mpirun -np 8  ./mpi_scaling strong reduce    10000000 20`

Аналогично можно повторить для `allreduce`:
- `mpirun -np 8  ./mpi_scaling strong allreduce 10000000 20`

Что сравнивать:
- `Total` vs число процессов,
- рост/падение `Comm share`.

### 7.3 Weak scaling (фиксированный Local N)
Запускаем так, чтобы **каждый процесс** обрабатывал одинаковый `N_arg`:

- `mpirun -np 1  ./mpi_scaling weak reduce    10000000 20`
- `mpirun -np 2  ./mpi_scaling weak reduce    10000000 20`
- `mpirun -np 4  ./mpi_scaling weak reduce    10000000 20`
- `mpirun -np 8  ./mpi_scaling weak reduce    10000000 20`

Что сравнивать:
- стабильность `Total` при росте `P`,
- увеличение `Comm` и `Comm share`.

---

## 8. Анализ производительности и выводы (что обычно наблюдается)

### 8.1 Strong scaling — где лучший выигрыш
Гибридный смысл strong scaling: уменьшение вычислений на процесс.
На практике:
- при небольшом `P` время падает заметно (compute делится между процессами),
- затем наступает “перелом”, когда `comm` начинает доминировать,
- после этого ускорение замедляется или почти исчезает.

То есть сильнее всего выигрыш обычно:
- когда `Global N` достаточно большой,
- а число процессов ещё не настолько большое, чтобы коммуникации стали основной частью времени.

### 8.2 Weak scaling — что ограничивает масштабируемость
В weak scaling локальные вычисления примерно постоянны, но:
- коммуникации **не исчезают** и обычно растут с `P`,
- поэтому `Total` часто увеличивается из-за `comm`.

### 8.3 MPI_Reduce vs MPI_Allreduce
Обычно:
- `MPI_Allreduce` даёт больше коммуникационных затрат, чем `MPI_Reduce`,
- разница особенно заметна при большом числе процессов,
- поэтому strong/weak scaling с `allreduce` часто “ломается” раньше (раньше растёт `Comm share`).

---

## 9. Практические ограничения алгоритма

Основные ограничения масштабируемости для такой задачи:

1) **Коммуникации становятся доминирующими** при большом числе процессов.  
2) **Низкая вычислительная нагрузка на процесс** (когда `local_N` становится маленьким) приводит к тому, что стоимость `Reduce/Allreduce` сопоставима или больше compute.  
3) В weak scaling общий объём данных растёт, и растёт давление на сеть (особенно если запуск на нескольких узлах).  
4) Итоговая скорость ограничена самым медленным процессом (поэтому берётся максимум таймингов по rank).

---

## 10. Что выводит программа

Программа выводит:

- режим масштабирования (`strong` или `weak`),
- тип коммуникации (`reduce` или `allreduce`),
- число процессов, `Global N` и фактический локальный размер на процесс,
- максимальные по процессам времена этапов:
  - генерация данных,
  - локальные вычисления,
  - коммуникации,
  - общее время,
- долю коммуникаций `Comm/Total`.

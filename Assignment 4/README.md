# Assignment 4
# Тема: Гибридные и распределённые параллельные вычисления
## Задание 1 (25 баллов)
Реализуйте CUDA-программу для вычисления суммы элементов массива с
использованием глобальной памяти. Сравните результат и время выполнения с
последовательной реализацией на CPU для массива размером 100 000 элементов.
## Задание 2 (25 баллов)
Реализуйте CUDA-программу для вычисления префиксной суммы (сканирования)
массива с использованием разделяемой памяти. Сравните время выполнения с
последовательной реализацией на CPU для массива размером 1 000 000 элементов.
## Задание 3 (25 баллов)
Реализуйте гибридную программу, в которой обработка массива выполняется
параллельно на CPU и GPU. Первую часть массива обработайте на CPU, вторую — на
GPU. Сравните время выполнения CPU-, GPU- и гибридной реализаций.
## Задание 4 (25 баллов)
Реализуйте распределённую программу с использованием MPI для обработки массива
данных. Разделите массив между процессами, выполните вычисления локально и
соберите результаты. Проведите замеры времени выполнения для 2, 4 и 8 процессов.
# Контрольные вопросы к Assignment 4
### 1. В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU?
CPU-вычисления подходят для последовательной логики, GPU — для массового параллелизма. Гибридные вычисления используют оба устройства: CPU управляет процессом и подготавливает данные, а GPU выполняет параллельные вычисления, что даёт более высокую производительность.
### 2. Для каких типов задач целесообразно распределять вычисления между CPU и GPU?
Гибридный подход эффективен для задач с большими массивами данных и чётко выделяемой параллельной частью, например численные расчёты, обработка изображений, моделирование и машинное обучение.
### 3. В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?
При синхронной передаче CPU ждёт завершения копирования данных. При асинхронной передаче копирование выполняется параллельно с вычислениями, и CPU не блокируется.
### 4. Почему асинхронная передача данных может повысить производительность программы?
Асинхронная передача позволяет перекрывать передачу данных и вычисления, уменьшая простой CPU и GPU и сокращая общее время выполнения программы.
### 5. Какие основные функции MPI используются для распределения и сбора данных между процессами?
Для обмена используются MPI_Send и MPI_Recv, для рассылки — MPI_Bcast, для распределения — MPI_Scatter, для сбора — MPI_Gather, для объединения данных — MPI_Reduce.
### 6. Как количество процессов MPI влияет на время выполнения программы и почему?
С ростом числа процессов вычисления ускоряются, но увеличиваются накладные расходы на обмен данными. После определённого момента добавление процессов перестаёт давать выигрыш.
### 7. Какие факторы ограничивают масштабируемость распределённых параллельных программ?
Масштабируемость ограничивают задержки сети, объём обмена данными, последовательные участки кода, неравномерная загрузка процессов и затраты на синхронизацию.
### 8. В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?
Они оправданы для больших и хорошо параллелизуемых задач. Неэффективны для небольших задач с частым обменом данными и преобладанием последовательных вычислений.

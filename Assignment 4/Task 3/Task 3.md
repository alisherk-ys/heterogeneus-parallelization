# Задание 3 — Гибридная обработка массива (CPU + GPU параллельно)
## 1. Цель задания

Нужно реализовать гибридную программу, где обработка массива выполняется одновременно на CPU и GPU:

- первая часть массива обрабатывается на CPU

- вторая часть массива обрабатывается на GPU

- сравнить время выполнения трёх вариантов:

  - CPU-only (всё на CPU)

  - GPU-only (всё на GPU)

  - Hybrid (часть на CPU + часть на GPU параллельно)

## 2. Что считается “обработкой массива” в этой работе

В качестве обработки используется простая операция над каждым элементом (аффинное преобразование).

Это типичная операция для тестов производительности:

- легко распараллеливается (каждый элемент независим),

- легко проверять правильность,

- подходит для CPU, GPU и гибрида.

## 3. Реализация CPU-only

CPU-версия проходит по всему массиву и считает y[i] = a*x[i] + b.

Если включён OpenMP, цикл распараллеливается:

`#pragma omp parallel for`

Если OpenMP не включён, код остаётся последовательным.

Время CPU измеряется через std::chrono вокруг вызова cpuAffine().

## 4. Реализация GPU-only

GPU-версия делает обработку целиком на GPU:

1. Выделяем память на GPU:

- `d_x, d_y`

2. Копируем входной массив x на GPU:

- `cudaMemcpy(d_x, h_x, ...)`

3. Запускаем kernel affineKernel, где каждый поток обрабатывает один элемент:

> int i = blockIdx.x * blockDim.x + threadIdx.x;
> 
> if (i < n) y[i] = a*x[i] + b;


4. Копируем результат y обратно на CPU:

- `cudaMemcpy(h_y_gpu, d_y, ...)`

## Замер времени GPU

В коде измеряются два времени:

- GPU-only kernel time — чистое время работы ядра (cudaEvent)

- GPU-only total time — полное время (H2D + kernel + D2H), измеренное через std::chrono

Это важно, потому что в реальных задачах копирование данных может занимать заметную часть времени.

## 5. Гибридная реализация (Hybrid)

Массив делится на две части:

- `N1 = N/2` — первая половина (CPU)

- `N2 = N - N1` — вторая половина (GPU)

### Ключевая идея: перекрыть работу CPU и GPU по времени

Чтобы CPU и GPU работали параллельно, используется:

- pinned host memory (cudaMallocHost) — чтобы cudaMemcpyAsync было действительно асинхронным

- CUDA stream — чтобы операции копирования и kernel выполнялись в одном потоке команд на GPU

# Задание 3 — Доступ к глобальной памяти на CUDA (коалесцированный vs некоалесцированный)

## 1. Цель задания

Нужно реализовать CUDA-программу для обработки массива размера **1 000 000** элементов так, чтобы она демонстрировала:

- **коалесцированный доступ** к глобальной памяти (coalesced),
- **некоалесцированный доступ** к глобальной памяти (non-coalesced / strided).

После этого требуется:

- замерить **время выполнения** обеих реализаций,
- сравнить результаты и показать, насколько некоалесцированный доступ замедляет работу.


## 2. Идея решения

В программе реализованы **два CUDA-ядра**, которые выполняют одинаковую операцию (умножение на `2.0f`), но **по-разному обращаются к памяти**.

### Версия 1: Коалесцированный доступ (`kernel_coalesced`)
- Поток с индексом `idx` читает `in[idx]` и пишет `out[idx]`.
- Потоки одного варпа (обычно 32 потока) обращаются к **последовательным адресам** памяти.

Это “идеальный” сценарий: GPU может объединять обращения в память в небольшое число транзакций.

### Версия 2: Некоалесцированный доступ (`kernel_noncoalesced`)
- Поток `idx` работает с индексом:
  - `j = (idx * stride) % n`
- То есть потоки обращаются к элементам массива **с шагом (stride)**, адреса “разбросаны”.

Из-за этого память читается/пишется менее эффективно: GPU чаще вынужден делать больше транзакций, и ядро заметно замедляется.



## 3. Реализация: коалесцированный доступ

### Ядро `kernel_coalesced`
- индекс:
  - `idx = blockIdx.x * blockDim.x + threadIdx.x`
- если `idx < n`, выполняется:
  - `out[idx] = in[idx] * 2.0f`


## 4. Реализация: некоалесцированный доступ

### Ядро `kernel_noncoalesced`
- индекс потока:
  - `idx = blockIdx.x * blockDim.x + threadIdx.x`
- вычисляем “разбросанный” индекс:
  - `j = (idx * stride) % n`
- и работаем уже с ним:
  - `out[j] = in[j] * 2.0f`


## 5. Замер времени выполнения

Для честного сравнения измеряется **только время ядра**, без учёта копирования данных CPU↔GPU.

Используется функция `timeKernel(...)`:

- делает **прогрев** (1 запуск + `cudaDeviceSynchronize()`),
- запускает ядро `iters` раз (в коде `iters = 300`),
- измеряет время через **CUDA Events**,
- возвращает **среднее время одного запуска**.


## 7. Проверка корректности

На CPU заранее считается эталон:

- `h_ref[i] = h_in[i] * 2.0f`

После последнего запуска ядра результат копируется в `h_out` и считается:

- `maxErr = max(|h_out[i] - h_ref[i]|)`

Если `maxErr <= 1e-4`, то выводится:

- `Correct = YES`


## 8. Что выводит программа

Программа печатает:

- среднее время коалесцированного ядра:
  - `Coalesced access avg time (ms)`
- среднее время некоалесцированного ядра:
  - `Non-coalesced access avg time (ms)`
- коэффициент замедления:
  - `Slowdown (non/coalesced) = noncoal_ms / coalesced_ms`
- ошибка и корректность:
  - `Max abs error`, `Correct`




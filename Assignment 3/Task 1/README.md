# Задание 1 — Поэлементная обработка массива на CUDA (Global vs Shared)

## 1. Цель задания

Нужно реализовать CUDA-программу, которая выполняет **поэлементную обработку массива** размером **1 000 000** элементов (в примере — *умножение каждого элемента на число `k`*).

Требуется сделать **две версии**:

- **Версия 1 (Global memory):** ядро работает только с глобальной памятью (чтение `in[idx]` и запись `out[idx]` напрямую).
- **Версия 2 (Shared memory):** данные блока сначала загружаются в **разделяемую память**, затем обрабатываются и записываются обратно.

После этого нужно сравнить:

- **время выполнения** `mul_global` и `mul_shared`,
- **корректность результата** (сравнение с эталоном на CPU).


## 2. Идея решения

Решение состоит из трёх логических частей:

1) подготовка данных на CPU + эталонный расчёт,  
2) обработка на GPU двумя ядрами (global и shared),  
3) замер времени и проверка корректности.


## 3. Реализация: версия на Global Memory

### CUDA-ядро `mul_global`
- Каждый поток обрабатывает **ровно один элемент** массива:
  - вычисляет индекс `idx`,
  - читает `in[idx]` из **global memory**,
  - записывает `out[idx]` в **global memory**.

Логика:
- `idx = blockIdx.x * blockDim.x + threadIdx.x`
- если `idx < n`, то:
  - `out[idx] = in[idx] * k`

## 4. Реализация: версия на Shared Memory

### CUDA-ядро `mul_shared`
В этом варианте каждый блок использует shared memory как “буфер”:

- создаётся shared-массив `s[]` размером `blockDim.x` (через `extern __shared__`),
- каждый поток копирует свой элемент из global → shared:
  - `s[tid] = in[idx]`
- `__syncthreads()` — чтобы все потоки блока дождались загрузки,
- выполняется обработка в shared:
  - `s[tid] *= k`
- снова `__syncthreads()` — чтобы все потоки завершили вычисление,
- запись результата shared → global:
  - `out[idx] = s[tid]`

## 5. Измерение времени выполнения (производительность)

Чтобы сравнение было честным, время считается **только для kernel**, без учёта копирования данных CPU↔GPU.

Используется функция `timeKernel(...)`:
- делает **прогрев GPU** (1 запуск + `cudaDeviceSynchronize()`),
- запускает ядро `iters` раз (в коде `iters = 200`),
- измеряет время через **CUDA Events** (`cudaEventRecord`, `cudaEventElapsedTime`),
- возвращает **среднее время одного запуска**: `ms / iters`.


## 6. Проверка корректности

После выполнения второго ядра (`mul_shared`) результат копируется обратно на CPU:

- `cudaMemcpy(h_out, d_out, ...)`

Далее сравниваем с эталоном `h_ref`:

- считаем максимальную абсолютную ошибку:
  - `max_err = max(|h_out[i] - h_ref[i]|)`
- если `max_err <= 1e-4`, выводим `Correct: YES`.


## 7. Вывод программы (что означает)

Программа печатает:

- `Global kernel time (ms)` — среднее время `mul_global`,
- `Shared kernel time (ms)` — среднее время `mul_shared`,
- `Max abs error` — максимум ошибки относительно CPU,
- `Correct` — прошла ли проверка,
- `Speed ratio (shared/global)`:
  - если > 1 → shared медленнее global,
  - если < 1 → shared быстрее global.


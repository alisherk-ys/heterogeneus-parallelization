# Задание 4 — Подбор оптимальной конфигурации CUDA (Grid/Block) и сравнение с неоптимальной

## 1. Цель задания

Нужно взять **одну из программ из предыдущих заданий** и подобрать для неё **оптимальные параметры конфигурации запуска CUDA**:

- размер блока потоков (**block size**),
- соответствующий размер сетки (**grid size**).

После подбора требуется:

- сравнить производительность **неоптимальной** конфигурации и **оптимизированной**,
- показать ускорение (speedup),
- убедиться, что результат вычислений остаётся корректным.

В этом решении в качестве базы взята задача **поэлементного сложения массивов**:

- `C[i] = A[i] + B[i]`, `N = 1 000 000`.


## 2. Идея решения

Решение строится как эксперимент:

1) Выбираем **неоптимальный baseline** (в коде это `block = 1024`).  
2) Перебираем набор кандидатов `block` (64…1024) и для каждого:
   - вычисляем `grid`,
   - измеряем время выполнения ядра,
   - выбираем вариант с **минимальным временем**.
3) Сравниваем:
   - время baseline,
   - время лучшей конфигурации,
   - считаем ускорение `speedup = unopt_ms / best_ms`.
4) Проверяем корректность результата (GPU vs CPU-эталон).


## 3. CUDA-ядро (что именно оптимизируем)

### Ядро `vec_add`
- Один поток обрабатывает один элемент:

- индекс:
  - `idx = blockIdx.x * blockDim.x + threadIdx.x`

- вычисление:
  - если `idx < n`, то `C[idx] = A[idx] + B[idx]`


## 4. Почему block/grid влияет на скорость

CUDA-ядро одно и то же, но GPU может работать по-разному в зависимости от конфигурации:

- **Слишком маленький block** → много блоков, больше накладных расходов, иногда хуже загрузка SM.
- **Слишком большой block** → может снижаться “заселённость” (occupancy):  
  меньше блоков одновременно помещается на SM из-за ограничений по ресурсам (регистры, warp’ы и т.д.).
- Поэтому оптимальный block — это компромисс, который максимально загружает GPU и эффективно использует память.

В задаче это проверяется **экспериментом**, потому что оптимум зависит от видеокарты и архитектуры.


## 5. Как измеряется время (методика)

Для сравнения используется функция `timeVecAdd(...)`:

- вычисляет `grid = (n + block - 1) / block`,
- делает **прогрев** (1 запуск + `cudaDeviceSynchronize()`),
- затем запускает ядро `iters` раз (в коде `iters = 300`),
- измеряет время через **CUDA Events**,
- возвращает среднее время одного запуска:  
  `avgMs = totalMs / iters`.


## 6. Что делает программа по шагам

1) Создаёт массивы `A`, `B` на CPU и считает эталон `Ref`:
   - `Ref[i] = A[i] + B[i]`
2) Копирует `A` и `B` на GPU.
3) Измеряет время **неоптимальной конфигурации**:
   - `unopt_block = 1024`
4) Перебирает кандидатов:
   - `{64, 128, 192, 256, 320, 384, 512, 768, 1024}`
   - для каждого печатает строку таблицы: block, grid, avg time
5) Выбирает `best_block` с минимальным временем.
6) Запускает ядро с лучшей конфигурацией и проверяет корректность:
   - считает `maxErr = max(|C[i] - Ref[i]|)`
7) Печатает сравнение и ускорение:
   - `Speedup (unopt/opt)`

## 7. Что выводит программа

Программа печатает:

- **baseline**:
  - `Unoptimized config: Block, Grid, Avg kernel time`
- **таблицу по всем кандидатам**:
  - `Block | Grid | Avg kernel (ms)`
- **лучшую конфигурацию**:
  - `Optimized config: best block/grid`
- **сравнение**:
  - `Unoptimized time`
  - `Optimized time`
  - `Speedup (unopt/opt)`
- **корректность**:
  - `Correct = YES/NO`
  - `Max abs error`


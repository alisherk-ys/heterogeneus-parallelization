# Задание 2 — Поэлементное сложение массивов на CUDA (влияние размера блока)

## 1. Цель задания

Нужно реализовать CUDA-программу для **поэлементного сложения двух массивов** `A` и `B` размера **1 000 000**:

- на выходе получить массив `C`, где `C[i] = A[i] + B[i]`.

Далее требуется **исследовать влияние размера блока потоков** (`blockDim.x`) на производительность:

- провести замеры времени выполнения CUDA-ядра **минимум для 3 разных размеров блока**,
- сравнить результаты и выбрать **оптимальный размер блока** (тот, который даёт минимальное время).


## 2. Идея решения

Решение строится так:

### GPU-вычисление (CUDA kernel)
- Выделяем память на GPU (`cudaMalloc`) под `dA`, `dB`, `dC`.
- Копируем `A` и `B` с CPU на GPU (`cudaMemcpy`).
- Запускаем ядро `vec_add<<<grid, block>>>()`, где:
  - `block` — число потоков в блоке (меняем по эксперименту),
  - `grid = ceil(N / block)` — число блоков.

### Эксперимент с разными block size
- Выбираем набор размеров блока (в коде: `128, 256, 512, 1024`).
- Для каждого block size:
  - считаем `grid`,
  - замеряем среднее время kernel через CUDA events,
  - выводим таблицу результатов,
  - запоминаем лучший вариант (минимальное время).

### Проверка корректности
- После эксперимента запускаем ядро с **лучшим block size** ещё раз,
- копируем результат `dC` на CPU,
- сравниваем с эталоном `hRef` (который посчитан на CPU),
- считаем `maxErr` и выводим `Correct: YES/NO`.



## 3. CUDA-ядро поэлементного сложения

### Ядро `vec_add`
- Каждый поток отвечает за **один индекс** `idx`:

- индекс вычисляется стандартно:
  - `idx = blockIdx.x * blockDim.x + threadIdx.x`

- если `idx < n`, выполняется операция:
  - `C[idx] = A[idx] + B[idx]`



## 4. Почему размер блока влияет на скорость

Размер блока (`block`) влияет на то, **как GPU распределяет работу**:

- **Малый block** → больше блоков, выше накладные расходы на планирование, может хуже загружаться GPU.
- **Слишком большой block** → может упасть “заселённость” (occupancy), может ограничить число одновременно активных блоков на SM из-за ресурсов (регистры/память), иногда ухудшает эффективность.
- **Оптимальный block** — баланс, который лучше всего загружает вычислительные блоки GPU под конкретную задачу и конкретную видеокарту.

Обычно часто хорошо работают **256 или 512**, но точно выясняется только экспериментом — поэтому в задании и требуется измерение.



## 5. Замер времени (как именно считается)

Для каждого `block` используется функция `timeVecAdd(...)`:

- **прогрев**: 1 запуск kernel + `cudaDeviceSynchronize()`  
  (чтобы убрать влияние “первого запуска” и инициализаций)

- далее замер через CUDA events:
  - запускаем kernel `iters` раз (в коде `iters = 300`)
  - измеряем общее время
  - возвращаем **среднее время одного запуска**:

`avgMs = totalMs / iters`


## 6. Что выводит программа

Программа печатает таблицу:

- `Block` — размер блока (потоков в блоке),
- `Grid` — число блоков,
- `Avg kernel (ms)` — среднее время одного запуска ядра.

Далее печатает итог:

- `Best block size = ...`
- `Max abs error = ...`
- `Correct = YES/NO`




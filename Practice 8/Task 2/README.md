# Задание 2 — Обработка массива на GPU с использованием CUDA

## 1. Цель задания

В этом задании нужно реализовать простейшую GPU-обработку массива с помощью CUDA.  
По условию требуется:

1. Скопировать данные с CPU на GPU.  
2. Реализовать CUDA-ядро, которое обрабатывает массив (в примере — умножение на 2).  
3. Скопировать обработанный массив обратно на CPU.  
4. Замерить время выполнения вычислений на GPU.

Это базовый пример, позволяющий понять:
- как данные передаются между CPU и GPU,
- как создаются и запускаются CUDA-ядра,
- как измерять время GPU-вычислений.


## 2. Идея решения

Задача — **поэлементно обработать массив**. Каждый элемент массива можно обрабатывать независимо, поэтому GPU подходит идеально: каждый поток может вычислять `a[i] *= 2`.

Общий алгоритм:

### **Шаг 1 — Подготовка массива на CPU**
Создаётся массив `h_data` размером `N = 1 000 000` и заполняется значениями индексов.

### **Шаг 2 — Выделение памяти на GPU**
На устройстве выделяется память через `cudaMalloc`.

### **Шаг 3 — Копирование данных CPU → GPU**
Используем `cudaMemcpy` для передачи массива.

### **Шаг 4 — Запуск CUDA kernel**
В ядре каждый поток вычисляет индекс `i` и, если он в пределах массива, выполняет: `a[i] *= 2`;


Выбор конфигурации:
- blockSize = 256 потоков  
- gridSize = `ceil(N / 256)`

Этого достаточно для покрытия всего массива.

### **Шаг 5 — Замер времени kernel**
Используются CUDA events:
- `cudaEventRecord(start)`
- запуск ядра
- `cudaEventRecord(stop)`
- вычисление времени в миллисекундах

### **Шаг 6 — Копирование данных GPU → CPU**
Результат передаётся обратно в `h_data`.

### **Шаг 7 — Проверка корректности**
Несколько значений выводятся на экран и сравниваются с ожидаемыми.

---

## 3. CUDA-ядро

```cpp
__global__ void multiply_by_two(float* a, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        a[i] *= 2.0f;
    }
}
```

Особенности:

- каждый поток работает со своим индексом,

- гонок данных нет — разные потоки пишут в разные области памяти,

- условие i < n защищает от выхода за границы массива.

## 4. Конфигурация Grid/Block
```cpp
const int blockSize = 256;
const int gridSize  = (N + blockSize - 1) / blockSize;
```
Эта формула гарантирует:

- если N не кратно 256, последний блок всё равно покроет оставшиеся элементы.

## 5. Замер времени на GPU

Время измеряется только для kernel, без учёта копирования данных.
```cpp
cudaEventRecord(start);
multiply_by_two<<<gridSize, blockSize>>>(d_data, N);
cudaEventRecord(stop);
cudaEventSynchronize(stop);
cudaEventElapsedTime(&kernel_ms, start, stop);
```
Результат — время в миллисекундах.

## 6. Проверка корректности

Выводятся несколько элементов массива:
```cpp
h_data[0]     = 0
h_data[1]     = 2
h_data[N-1]   = 1999998
```
Ожидается, что каждый элемент стал `2*i`.



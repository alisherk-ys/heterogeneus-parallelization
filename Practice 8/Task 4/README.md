# Задание 4 — Анализ производительности (CPU vs GPU vs Hybrid)

## 1. Цель задания

В этом задании нужно **сравнить производительность** трёх способов обработки массива (операция: умножение каждого элемента на 2):

1. **CPU (OpenMP)** — обработка всего массива на процессоре с распараллеливанием.
2. **GPU (CUDA)** — обработка всего массива на видеокарте, включая передачу данных.
3. **Hybrid (CPU + GPU)** — половина массива обрабатывается на CPU, половина — на GPU **одновременно**.

Также требуется выполнить **анализ**, когда гибридный подход даёт наибольший выигрыш.


## 2. Что именно сравниваем по времени

Важно: измеряются разные типы “времени”, и в коде это сделано явно.

### 2.1 CPU (OpenMP)
Замеряется только вычисление на CPU (цикл умножения), без копирований:

- запуск параллельного цикла `#pragma omp parallel for`
- время берётся через `std::chrono`

Функция: `run_cpu_openmp(...)`.

### 2.2 GPU (CUDA, end-to-end)
Для GPU измеряется **время “от и до”**, то есть:

- копирование данных CPU → GPU (H2D),
- выполнение CUDA kernel,
- копирование результата GPU → CPU (D2H).

Это принципиально важно, потому что в реальных задачах передачи данных часто занимают заметную долю времени.

Функция: `run_gpu_end_to_end(...)`.

### 2.3 Hybrid (CPU + GPU, end-to-end)
Гибридный режим устроен так:

- первая половина массива обрабатывается на CPU (OpenMP),
- вторая половина обрабатывается на GPU:
  - H2D (только второй половины),
  - kernel (только второй половины),
  - D2H (только второй половины),
- CPU и GPU выполняются **одновременно** через `#pragma omp parallel sections`.

Функция: `run_hybrid_end_to_end(...)`.



## 3. Как реализовано сравнение (логика программы)

### 3.1 Данные и размеры тестов
Программа тестирует несколько размеров массива (от меньших к большим):

- `sizes = { 2^16, 2^18, 2^20, 2^22 }`

Для каждого размера:
- создаётся исходный массив `base`,
- данные заполняются случайными числами через `fill_data(...)`.

### 3.2 Повторы и выбор лучшего времени
Чтобы уменьшить шум измерений, используется несколько повторов:

- `repeats = 5`

Для каждого режима (CPU/GPU/Hybrid) измерение запускается 5 раз, и берётся **лучшее** (минимальное) время.

Это нужно, потому что на практике замеры могут “плавать” из-за:
- фоновых процессов,
- динамических частот CPU/GPU,
- прогрева кэшей и GPU.

### 3.3 Прогрев GPU
Перед основными измерениями GPU делается один “прогревочный” запуск:

- это уменьшает влияние первого запуска (инициализации контекста/драйвера).


## 4. Проверка корректности

Для каждого режима вычисляется результат и проверяется функция `check_mul2(...)`.

Проверка подтверждает, что для каждого элемента выполняется:

- `after[i] ≈ before[i] * 2`

Сравнение идёт с допуском `eps`, чтобы корректно работать с `float`.

## 5. Ускорение (speedup)

После получения лучших времен рассчитываются ускорения относительно CPU:

- `GPU speedup = CPU_time / GPU_time`
- `Hybrid speedup = CPU_time / Hybrid_time`

Это показывает, во сколько раз GPU и гибридный режим быстрее CPU на том же размере данных.

## 6. Что выводит программа

Программа печатает:

- для каждого размера массива:
  - лучшее время CPU (OpenMP) + статус проверки корректности,
  - лучшее время GPU (CUDA, end-to-end) + статус проверки,
  - лучшее время Hybrid (CPU+GPU) + статус проверки,
  - ускорение GPU и Hybrid относительно CPU,
  - режим-победитель (кто оказался самым быстрым на этом размере).

## 7. Анализ производительности: когда Hybrid даёт максимум

Гибридный подход эффективен не всегда. Он даёт максимальный выигрыш тогда, когда выполняются несколько условий одновременно.

### 7.1 Когда hybrid обычно выигрывает
Hybrid наиболее выгоден, когда:

1) **CPU и GPU оба достаточно загружены**, и их вычисления реально идут параллельно.  
   То есть CPU-часть не слишком маленькая и GPU-часть не слишком маленькая.

2) **Передача данных в GPU не доминирует** над вычислениями.  
   В гибридном режиме копируется только половина массива, поэтому затраты на H2D/D2H меньше, чем у полного GPU режима.

3) **Баланс нагрузки близок к равному по времени**, а не по размеру.  
   Деление “50/50 по элементам” может быть неидеальным, потому что GPU обычно быстрее CPU на чистых вычислениях.  
   В реальности лучший баланс часто достигается, когда CPU получает меньшую долю данных, а GPU — большую.

### 7.2 Когда hybrid даёт слабый эффект или проигрывает
Hybrid может быть невыгоден, если:

1) Размер данных маленький и overhead на управление/копирование слишком велик.  
   Тогда CPU (OpenMP) может быть быстрее из-за отсутствия H2D/D2H.

2) GPU-время в основном уходит на копирование данных, а вычисление очень простое (как `*2`).  
   Тогда GPU режим может не дать большого выигрыша, и hybrid тоже будет ограничен копированием второй половины.

3) CPU и GPU работают не полностью параллельно из-за синхронизаций.  
   Например, если где-то есть лишний `cudaDeviceSynchronize()` или ожидание, то параллельность ухудшается.


Сравнение проводится на нескольких размерах массива, с повторами и проверкой корректности.  
По результатам можно сделать вывод, при каких размерах данных и соотношениях затрат (вычисления vs копирование) гибридный подход становится наиболее выгодным.
